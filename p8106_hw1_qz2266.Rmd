---
title: "p8106_hw1_qz2266"
author: "Qing Zhou"
date: "2023-02-21"
output: github_document
---


```{r setup, include=FALSE}
library(tidyverse)
library(dplyr) 
library(glmnet)
library(caret)
library(corrplot)
library(plotmo)

knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```



### Data Import and cleaning

In this exercise, we predict the sale price of a house using its other characteristics. The training data are in “housing train.csv”, and the test data are in “housing test.csv”.
```{r}
# read in training data
train = read.csv("data/housing_training.csv") %>% 
janitor::clean_names()
train = na.omit(train)

# read in test data
test = read.csv("data/housing_test.csv") %>% 
janitor::clean_names()
test = na.omit(test)

# create covariates matrix for training and test
x_train = model.matrix(sale_price ~ ., train)[,-1]
y_train = train$sale_price
x_test <- model.matrix(sale_price ~ ., test)[ ,-1]
y_test <- test$sale_price
```


Check for potential collinearities among predictors in training data
```{r correlation plot}
# Correlation plot for all predictors
corrplot(cor(x_train), method = "circle", type = "full", tl.cex = 0.5)
```
From the correlation plot we can see there are high correlations between some of the covariates. This high correlation might cause collinearity issue. To fix the potential multicollinearity issue, regularization methods such as lasso, elastic net, or partial least squares could be employed, other than linear model. 



### a). Linear model 
```{r}
set.seed(1)

lm_fit = lm(sale_price ~ ., 
            data = train,
            method = "lm",
            trControl = trainControl(method = "repeatedcv", number = 10, repeats = 5))
summary(lm_fit)

# prediction
pred_lm = predict(lm_fit, newdata = test)

# test error


lm_rmse = RMSE(pred_lm, test$sale_price); lm_rmse
mse = (lm_rmse^2); mse
```
Pros and cons of the linear model: 1. This model is quite straightforward and easy to fit.The estimates are BLUE. However, this model is still quite complicated with too many predictors. Moreover, there is potential multicollinearity issue and overfitting problem. 



### b). Lasso model

#### lasso model 1 based on lambda min
```{r}
set.seed(1)

lasso_fit = train(x_train, y_train, 
                    method = "glmnet",
                    tuneGrid = expand.grid(alpha = 1,
                                           lambda = exp(seq(-2, 8, length = 100))),
                    trControl = trainControl(method = "repeatedcv", number = 10, repeats = 5))

plot(lasso_fit, xTrans = log)

# optimal tuning parameters
lasso_fit$bestTune
# show coefficients
coef(lasso_fit$finalModel, lasso_fit$bestTune$lambda)

# prediction
pred_lasso = predict(lasso_fit, newdata = x_test)
# test error
lasso_mse = mean((pred_lasso - y_test)^2); lasso_mse
# number of predictors
num_coef = coef(lasso_fit$finalModel, lasso_fit$bestTune$lambda) 
sum(num_coef != 0) - 1
```


#### lasso model 2 based on 1SE
```{r}
set.seed(1)

lasso_1se = train(x_train, y_train, 
                  method = "glmnet",
                  tuneGrid = expand.grid(alpha = 1,
                                         lambda = exp(seq(-2, 8, length = 100))),
                  trControl =  trainControl(method = "repeatedcv", selectionFunction = "oneSE", number = 10, repeats = 5))
                  
# optimal tuning parameters based on 1se rule
lasso_1se$bestTune
# show coefficients 
coef(lasso_1se$finalModel, lasso_1se$bestTune$lambda)
```

```{r}
# prediction
pred_lasso_1se = predict(lasso_1se, newdata = x_test)
# test error
lasso_1se_mse = mean((pred_lasso_1se - y_test)^2); lasso_1se_mse
# number of predictors
num_coef_1se = coef(lasso_1se$finalModel, lasso_1se$bestTune$lambda) 
sum(num_coef_1se != 0) - 1
```

There are 37 predictors in lasso model 1 based on lambda min and 36 predictors in lasso model 2 based on 1se rule.  The selected turing parameter for lowest cv rmse is 64.18 while the 1se rule gives lambda of 395.36. Lasso model 2 based on 1se rule has smaller test MSE which is `r lasso_1se_mse` than lasso model 1 based on lambda min which is `r lasso_mse`. Therefore, lasso model 2 based on 1se is better.



### c). Elastic Net model

#### Elastice net model 1
```{r}
set.seed(1)

elnet_fit = train(x_train, y_train, 
                  method = "glmnet",
                  tuneGrid = expand.grid(alpha = seq(0, 1, length = 21),
                                         lambda = exp(seq(-2, 8, length = 50))),
                  trControl = trainControl(method = "repeatedcv", number = 10, repeats = 5))

# visualization
myCol <- rainbow(25)
myPar <- list(superpose.symbol = list(col = myCol),
superpose.line = list(col = myCol))
plot(elnet_fit, par.settings = myPar)

# tuning parameter 
elnet_fit$bestTune
# show coefficients
coef(elnet_fit$finalModel, elnet_fit$bestTune$lambda)
```

```{r}
# prediction
pred_elnet = predict(elnet_fit, newdata = x_test)
# test error
elnet_mse = mean(RMSE(pred_elnet, y_test)^2); elnet_mse

```

#### Elastic net model 2 based on 1se
```{r}
set.seed(1)
# try to fit elastic net model applying 1se rule to select tuning parameters
elnet_model_1se = train(x_train, y_train, 
                    method = "glmnet",
                    tuneGrid = expand.grid(alpha = seq(0, 1, length = 21),
                                           lambda = exp(seq(-2, 8, length = 50))),
                    trControl =  trainControl(method = "repeatedcv", selectionFunction = "oneSE", number = 10, repeats = 5))

# tuning parameters
elnet_model_1se$bestTune
# show coefficients 
coef(elnet_model_1se$finalModel, elnet_model_1se$bestTune$lambda)
```
The selected tuning parameters of elastic net model 1 is alpha = 0.05 and lambda = 582.5 and test error is `r elnet_mse`.  If 1se rule is applied to elastic net model, the tuning parameters is alpha =  0 and lambda is 2980.96. 
As we know, elastic net allows us to tune the alpha parameter where 𝞪 = 0 corresponds to ridge and 𝞪 = 1 to lasso. That means we can choose an alpha value between 0 and 1 to optimize the elastic net. In elastic net model 2, we found alpha = 0. Therefore, the penalty function reduces to the ridge term. Thus, we don't need to apply 1se rule to select tuning parameters in this elastic net model. It doesn't help to optimize this model. 





